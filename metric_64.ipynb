{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660eb98b-1bdd-4179-8018-f25333330518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:03:04.646859Z",
     "iopub.status.busy": "2024-12-15T08:03:04.646278Z",
     "iopub.status.idle": "2024-12-15T08:04:09.940797Z",
     "shell.execute_reply": "2024-12-15T08:04:09.939807Z",
     "shell.execute_reply.started": "2024-12-15T08:03:04.646825Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-fidelity\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (10.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (1.13.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (0.18.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from torch-fidelity) (4.66.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torch-fidelity) (68.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torch-fidelity) (0.41.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0->torch->torch-fidelity) (3.29.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0->torch->torch-fidelity) (18.1.4)\n",
      "Collecting torch (from torch-fidelity)\n",
      "  Using cached torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (2021.11.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torch-fidelity)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch->torch-fidelity) (12.1.105)\n",
      "Collecting triton==2.3.0 (from torch->torch-fidelity)\n",
      "  Using cached triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-fidelity) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch->torch-fidelity) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch->torch-fidelity) (1.3.0)\n",
      "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Using cached torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.6 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torch-fidelity\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.2.0.103\n",
      "    Uninstalling nvidia-cusparse-cu12-12.2.0.103:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.2.0.103\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.4.107\n",
      "    Uninstalling nvidia-curand-cu12-10.3.4.107:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.4.107\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.12.1\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.12.1:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.12.1\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.3.101\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.3.101:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.3.101\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.3.107\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.3.107:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.3.107\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.3.101\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.3.101:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.3.101\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.3.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.3.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.3.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.5.4.101\n",
      "    Uninstalling nvidia-cusolver-cu12-11.5.4.101:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.5.4.101\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.7.29\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.7.29:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.7.29\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 torch-2.3.0 torch-fidelity-0.3.0 triton-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics[image] in /opt/conda/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (2.3.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (0.11.2)\n",
      "Requirement already satisfied: scipy>1.0.0 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (1.13.0)\n",
      "Requirement already satisfied: torch-fidelity<=0.4.0 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (0.3.0)\n",
      "Requirement already satisfied: torchvision>=0.8 in /opt/conda/lib/python3.9/site-packages (from torchmetrics[image]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (3.14.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (2021.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics[image]) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics[image]) (12.3.101)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (10.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->torchmetrics[image]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.10.0->torchmetrics[image]) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.6 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch-fidelity\n",
    "!pip install torchmetrics[image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4d8fb6-9167-4ef6-89af-03dc67409449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:04:09.943536Z",
     "iopub.status.busy": "2024-12-15T08:04:09.943150Z",
     "iopub.status.idle": "2024-12-15T08:04:09.947753Z",
     "shell.execute_reply": "2024-12-15T08:04:09.947274Z",
     "shell.execute_reply.started": "2024-12-15T08:04:09.943508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_images_folder = './e2e_64/96/images'\n",
    "orig_images_folder = './e2e_64/vae'\n",
    "\n",
    "gen_image_prefix = 'output_'\n",
    "orig_images_prefix = 'output_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e94890-08c3-4d80-92f2-464bcf57869f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:04:09.948799Z",
     "iopub.status.busy": "2024-12-15T08:04:09.948616Z",
     "iopub.status.idle": "2024-12-15T08:04:17.476617Z",
     "shell.execute_reply": "2024-12-15T08:04:17.472630Z",
     "shell.execute_reply.started": "2024-12-15T08:04:09.948784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./e2e_64/96/images\n",
      "output_gpu_0_0_0_3.png\n",
      "output_gpu_0_0_6_3.png\n",
      "output_gpu_0_0_2_3.png\n",
      "output_gpu_0_0_24_1.png\n",
      "output_gpu_0_0_15_3.png\n",
      "output_gpu_0_0_5_1.png\n",
      "output_gpu_0_0_12_3.png\n",
      "output_gpu_0_0_7_3.png\n",
      "output_gpu_0_0_16_2.png\n",
      "output_gpu_0_0_15_1.png\n",
      "output_gpu_0_0_18_1.png\n",
      "output_gpu_0_0_9_3.png\n",
      "output_gpu_0_0_20_3.png\n",
      "output_gpu_0_0_8_3.png\n",
      "output_gpu_0_0_4_0.png\n",
      "output_gpu_0_0_14_1.png\n",
      "output_gpu_0_0_15_2.png\n",
      "output_gpu_0_0_0_1.png\n",
      "output_gpu_0_0_24_2.png\n",
      "output_gpu_0_0_17_2.png\n",
      "output_gpu_0_0_21_2.png\n",
      "output_gpu_0_0_18_2.png\n",
      "output_gpu_0_0_17_3.png\n",
      "output_gpu_0_0_11_3.png\n",
      "output_gpu_0_0_8_2.png\n",
      "output_gpu_0_0_10_1.png\n",
      "output_gpu_0_0_2_0.png\n",
      "output_gpu_0_0_13_1.png\n",
      "output_gpu_0_0_9_2.png\n",
      "output_gpu_0_0_14_3.png\n",
      "output_gpu_0_0_18_3.png\n",
      "output_gpu_0_0_1_3.png\n",
      "output_gpu_0_0_6_1.png\n",
      "output_gpu_0_0_18_0.png\n",
      "output_gpu_0_0_14_0.png\n",
      "output_gpu_0_0_1_0.png\n",
      "output_gpu_0_0_4_1.png\n",
      "output_gpu_0_0_11_1.png\n",
      "output_gpu_0_0_23_3.png\n",
      "output_gpu_0_0_1_2.png\n",
      "output_gpu_0_0_19_3.png\n",
      "output_gpu_0_0_7_1.png\n",
      "output_gpu_0_0_22_2.png\n",
      "output_gpu_0_0_20_0.png\n",
      "output_gpu_0_0_13_2.png\n",
      "output_gpu_0_0_14_2.png\n",
      "output_gpu_0_0_11_0.png\n",
      "output_gpu_0_0_16_1.png\n",
      "output_gpu_0_0_9_0.png\n",
      "output_gpu_0_0_15_0.png\n",
      "output_gpu_0_0_16_0.png\n",
      "output_gpu_0_0_10_0.png\n",
      "output_gpu_0_0_5_0.png\n",
      "output_gpu_0_0_10_3.png\n",
      "output_gpu_0_0_2_1.png\n",
      "output_gpu_0_0_3_2.png\n",
      "output_gpu_0_0_13_3.png\n",
      "output_gpu_0_0_21_3.png\n",
      "output_gpu_0_0_0_0.png\n",
      "output_gpu_0_0_20_2.png\n",
      "output_gpu_0_0_4_2.png\n",
      "output_gpu_0_0_7_2.png\n",
      "output_gpu_0_0_8_1.png\n",
      "output_gpu_0_0_24_0.png\n",
      "output_gpu_0_0_12_2.png\n",
      "output_gpu_0_0_6_2.png\n",
      "output_gpu_0_0_22_1.png\n",
      "output_gpu_0_0_8_0.png\n",
      "output_gpu_0_0_3_3.png\n",
      "output_gpu_0_0_3_0.png\n",
      "output_gpu_0_0_19_2.png\n",
      "output_gpu_0_0_6_0.png\n",
      "output_gpu_0_0_11_2.png\n",
      "output_gpu_0_0_16_3.png\n",
      "output_gpu_0_0_19_0.png\n",
      "output_gpu_0_0_3_1.png\n",
      "output_gpu_0_0_24_3.png\n",
      "output_gpu_0_0_1_1.png\n",
      "output_gpu_0_0_5_3.png\n",
      "output_gpu_0_0_20_1.png\n",
      "output_gpu_0_0_7_0.png\n",
      "output_gpu_0_0_17_0.png\n",
      "output_gpu_0_0_23_0.png\n",
      "output_gpu_0_0_9_1.png\n",
      "output_gpu_0_0_5_2.png\n",
      "output_gpu_0_0_13_0.png\n",
      "output_gpu_0_0_12_1.png\n",
      "output_gpu_0_0_22_3.png\n",
      "output_gpu_0_0_2_2.png\n",
      "output_gpu_0_0_21_0.png\n",
      "output_gpu_0_0_0_2.png\n",
      "output_gpu_0_0_19_1.png\n",
      "output_gpu_0_0_17_1.png\n",
      "output_gpu_0_0_22_0.png\n",
      "output_gpu_0_0_12_0.png\n",
      "output_gpu_0_0_4_3.png\n",
      "output_gpu_0_0_10_2.png\n",
      "output_gpu_0_0_23_1.png\n",
      "output_gpu_0_0_21_1.png\n",
      "output_gpu_0_0_23_2.png\n",
      "./e2e_64/vae\n",
      "output_vae_gpu_0_0_0_0.png\n",
      "output_vae_gpu_0_0_16_3.png\n",
      "output_vae_gpu_0_0_24_1.png\n",
      "output_vae_gpu_0_0_15_1.png\n",
      "output_vae_gpu_0_0_22_1.png\n",
      "output_vae_gpu_0_0_8_3.png\n",
      "output_vae_gpu_0_0_1_0.png\n",
      "output_vae_gpu_0_0_18_2.png\n",
      "output_vae_gpu_0_0_0_2.png\n",
      "output_vae_gpu_0_0_6_2.png\n",
      "output_vae_gpu_0_0_5_2.png\n",
      "output_vae_gpu_0_0_20_2.png\n",
      "output_vae_gpu_0_0_11_0.png\n",
      "output_vae_gpu_0_0_4_3.png\n",
      "output_vae_gpu_0_0_4_1.png\n",
      "output_vae_gpu_0_0_2_2.png\n",
      "output_vae_gpu_0_0_6_3.png\n",
      "output_vae_gpu_0_0_9_2.png\n",
      "output_vae_gpu_0_0_2_1.png\n",
      "output_vae_gpu_0_0_3_1.png\n",
      "output_vae_gpu_0_0_24_2.png\n",
      "output_vae_gpu_0_0_11_1.png\n",
      "output_vae_gpu_0_0_10_1.png\n",
      "output_vae_gpu_0_0_15_3.png\n",
      "output_vae_gpu_0_0_14_2.png\n",
      "output_vae_gpu_0_0_23_0.png\n",
      "output_vae_gpu_0_0_9_0.png\n",
      "output_vae_gpu_0_0_20_3.png\n",
      "output_vae_gpu_0_0_11_2.png\n",
      "output_vae_gpu_0_0_19_0.png\n",
      "output_vae_gpu_0_0_7_0.png\n",
      "output_vae_gpu_0_0_6_0.png\n",
      "output_vae_gpu_0_0_5_1.png\n",
      "output_vae_gpu_0_0_5_0.png\n",
      "output_vae_gpu_0_0_12_3.png\n",
      "output_vae_gpu_0_0_20_1.png\n",
      "output_vae_gpu_0_0_22_3.png\n",
      "output_vae_gpu_0_0_7_3.png\n",
      "output_vae_gpu_0_0_21_2.png\n",
      "output_vae_gpu_0_0_12_1.png\n",
      "output_vae_gpu_0_0_8_2.png\n",
      "output_vae_gpu_0_0_19_1.png\n",
      "output_vae_gpu_0_0_24_0.png\n",
      "output_vae_gpu_0_0_15_2.png\n",
      "output_vae_gpu_0_0_17_2.png\n",
      "output_vae_gpu_0_0_1_1.png\n",
      "output_vae_gpu_0_0_22_2.png\n",
      "output_vae_gpu_0_0_17_0.png\n",
      "output_vae_gpu_0_0_1_2.png\n",
      "output_vae_gpu_0_0_3_0.png\n",
      "output_vae_gpu_0_0_24_3.png\n",
      "output_vae_gpu_0_0_8_1.png\n",
      "output_vae_gpu_0_0_12_2.png\n",
      "output_vae_gpu_0_0_4_2.png\n",
      "output_vae_gpu_0_0_9_1.png\n",
      "output_vae_gpu_0_0_17_3.png\n",
      "output_vae_gpu_0_0_7_2.png\n",
      "output_vae_gpu_0_0_13_2.png\n",
      "output_vae_gpu_0_0_18_1.png\n",
      "output_vae_gpu_0_0_8_0.png\n",
      "output_vae_gpu_0_0_2_3.png\n",
      "output_vae_gpu_0_0_19_3.png\n",
      "output_vae_gpu_0_0_10_0.png\n",
      "output_vae_gpu_0_0_21_0.png\n",
      "output_vae_gpu_0_0_16_0.png\n",
      "output_vae_gpu_0_0_23_1.png\n",
      "output_vae_gpu_0_0_0_3.png\n",
      "output_vae_gpu_0_0_10_3.png\n",
      "output_vae_gpu_0_0_14_0.png\n",
      "output_vae_gpu_0_0_6_1.png\n",
      "output_vae_gpu_0_0_1_3.png\n",
      "output_vae_gpu_0_0_13_3.png\n",
      "output_vae_gpu_0_0_13_0.png\n",
      "output_vae_gpu_0_0_23_2.png\n",
      "output_vae_gpu_0_0_14_3.png\n",
      "output_vae_gpu_0_0_13_1.png\n",
      "output_vae_gpu_0_0_11_3.png\n",
      "output_vae_gpu_0_0_16_1.png\n",
      "output_vae_gpu_0_0_22_0.png\n",
      "output_vae_gpu_0_0_17_1.png\n",
      "output_vae_gpu_0_0_18_3.png\n",
      "output_vae_gpu_0_0_5_3.png\n",
      "output_vae_gpu_0_0_16_2.png\n",
      "output_vae_gpu_0_0_14_1.png\n",
      "output_vae_gpu_0_0_12_0.png\n",
      "output_vae_gpu_0_0_23_3.png\n",
      "output_vae_gpu_0_0_3_3.png\n",
      "output_vae_gpu_0_0_21_3.png\n",
      "output_vae_gpu_0_0_10_2.png\n",
      "output_vae_gpu_0_0_9_3.png\n",
      "output_vae_gpu_0_0_21_1.png\n",
      ".ipynb_checkpoints\n",
      "output_vae_gpu_0_0_0_1.png\n",
      "output_vae_gpu_0_0_3_2.png\n",
      "output_vae_gpu_0_0_4_0.png\n",
      "output_vae_gpu_0_0_18_0.png\n",
      "output_vae_gpu_0_0_20_0.png\n",
      "output_vae_gpu_0_0_7_1.png\n",
      "output_vae_gpu_0_0_15_0.png\n",
      "output_vae_gpu_0_0_19_2.png\n",
      "output_vae_gpu_0_0_2_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
      "100%|██████████| 91.2M/91.2M [00:00<00:00, 331MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "# 이미지 불러오기 및 텐서로 변환하는 함수\n",
    "def load_images_from_folder(folder, start_dir):\n",
    "    images = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),  # 이미지 크기를 128x128로 조정\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: (x * 255).byte())\n",
    "    ])\n",
    "    print(folder)\n",
    "    for filename in os.listdir(folder):\n",
    "        print(filename)\n",
    "        if filename.startswith(start_dir):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            \n",
    "            if not os.path.isfile(img_path):\n",
    "                    continue\n",
    "                    \n",
    "            with Image.open(img_path) as img:                    \n",
    "                img = transform(img)\n",
    "                images.append(img) \n",
    "    return torch.stack(images)\n",
    "\n",
    "# vae_로 시작하는 이미지 불러오기\n",
    "vae_images = load_images_from_folder(generate_images_folder, gen_image_prefix)\n",
    "\n",
    "# orig_로 시작하는 이미지 불러오기\n",
    "orig_images = load_images_from_folder(orig_images_folder, orig_images_prefix)\n",
    "\n",
    "# FID 인스턴스 생성\n",
    "fid = FrechetInceptionDistance(feature=64)\n",
    "\n",
    "# 실제(real) 이미지로 orig_ 이미지 업데이트\n",
    "fid.update(orig_images, real=True)\n",
    "\n",
    "# 생성된(generated) 이미지로 vae_ 이미지 업데이트\n",
    "fid.update(vae_images, real=False)\n",
    "\n",
    "# FID 계산\n",
    "fid_value = fid.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8151e498-b4df-4100-a1e5-5c3aef9ac272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:04:17.479385Z",
     "iopub.status.busy": "2024-12-15T08:04:17.478744Z",
     "iopub.status.idle": "2024-12-15T08:04:17.487765Z",
     "shell.execute_reply": "2024-12-15T08:04:17.487228Z",
     "shell.execute_reply.started": "2024-12-15T08:04:17.479353Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7262)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34b1e42-b688-4fa1-8e82-3b44b9819c28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:04:17.489040Z",
     "iopub.status.busy": "2024-12-15T08:04:17.488554Z",
     "iopub.status.idle": "2024-12-15T08:04:17.496878Z",
     "shell.execute_reply": "2024-12-15T08:04:17.496214Z",
     "shell.execute_reply.started": "2024-12-15T08:04:17.489022Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_inception_score(images, batch_size=32, splits=10):\n",
    "       # Inception 모델 로드\n",
    "    inception_model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT, transform_input=False)\n",
    "    inception_model.eval()\n",
    "\n",
    "    # 이미지 변환 정의\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),        # 텐서를 PIL 이미지로 변환\n",
    "        transforms.Resize((299, 299)),  # 이미지 크기 조정\n",
    "        transforms.ToTensor(),          # 텐서로 변환\n",
    "    ])\n",
    "\n",
    "    # 이미지 텐서를 batch_size로 나누기\n",
    "    n_images = images.size(0)\n",
    "    preds = []\n",
    "    for i in range(0, n_images, batch_size):\n",
    "        batch = images[i:i + batch_size]\n",
    "        batch = torch.stack([preprocess(img) for img in batch])  # 각 이미지를 전처리\n",
    "        batch = batch.float() / 255.0  # 0~1 범위로 정규화\n",
    "        with torch.no_grad():\n",
    "            pred = inception_model(batch)\n",
    "            preds.append(F.softmax(pred, dim=1).cpu())\n",
    "\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "\n",
    "    # Inception Score 계산\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (n_images // splits): (i + 1) * (n_images // splits), :]\n",
    "        py = torch.mean(part, dim=0)\n",
    "        scores.append(torch.exp(torch.mean(torch.sum(part * torch.log(part / py), dim=1))))\n",
    "\n",
    "    return torch.mean(torch.tensor(scores)), torch.std(torch.tensor(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64db5505-b48b-446d-b536-7c6cc8dc8587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:04:17.498092Z",
     "iopub.status.busy": "2024-12-15T08:04:17.497661Z",
     "iopub.status.idle": "2024-12-15T08:04:32.146863Z",
     "shell.execute_reply": "2024-12-15T08:04:32.146085Z",
     "shell.execute_reply.started": "2024-12-15T08:04:17.498074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./e2e_64/96/images\n",
      "output_gpu_0_0_0_3.png\n",
      "output_gpu_0_0_6_3.png\n",
      "output_gpu_0_0_2_3.png\n",
      "output_gpu_0_0_24_1.png\n",
      "output_gpu_0_0_15_3.png\n",
      "output_gpu_0_0_5_1.png\n",
      "output_gpu_0_0_12_3.png\n",
      "output_gpu_0_0_7_3.png\n",
      "output_gpu_0_0_16_2.png\n",
      "output_gpu_0_0_15_1.png\n",
      "output_gpu_0_0_18_1.png\n",
      "output_gpu_0_0_9_3.png\n",
      "output_gpu_0_0_20_3.png\n",
      "output_gpu_0_0_8_3.png\n",
      "output_gpu_0_0_4_0.png\n",
      "output_gpu_0_0_14_1.png\n",
      "output_gpu_0_0_15_2.png\n",
      "output_gpu_0_0_0_1.png\n",
      "output_gpu_0_0_24_2.png\n",
      "output_gpu_0_0_17_2.png\n",
      "output_gpu_0_0_21_2.png\n",
      "output_gpu_0_0_18_2.png\n",
      "output_gpu_0_0_17_3.png\n",
      "output_gpu_0_0_11_3.png\n",
      "output_gpu_0_0_8_2.png\n",
      "output_gpu_0_0_10_1.png\n",
      "output_gpu_0_0_2_0.png\n",
      "output_gpu_0_0_13_1.png\n",
      "output_gpu_0_0_9_2.png\n",
      "output_gpu_0_0_14_3.png\n",
      "output_gpu_0_0_18_3.png\n",
      "output_gpu_0_0_1_3.png\n",
      "output_gpu_0_0_6_1.png\n",
      "output_gpu_0_0_18_0.png\n",
      "output_gpu_0_0_14_0.png\n",
      "output_gpu_0_0_1_0.png\n",
      "output_gpu_0_0_4_1.png\n",
      "output_gpu_0_0_11_1.png\n",
      "output_gpu_0_0_23_3.png\n",
      "output_gpu_0_0_1_2.png\n",
      "output_gpu_0_0_19_3.png\n",
      "output_gpu_0_0_7_1.png\n",
      "output_gpu_0_0_22_2.png\n",
      "output_gpu_0_0_20_0.png\n",
      "output_gpu_0_0_13_2.png\n",
      "output_gpu_0_0_14_2.png\n",
      "output_gpu_0_0_11_0.png\n",
      "output_gpu_0_0_16_1.png\n",
      "output_gpu_0_0_9_0.png\n",
      "output_gpu_0_0_15_0.png\n",
      "output_gpu_0_0_16_0.png\n",
      "output_gpu_0_0_10_0.png\n",
      "output_gpu_0_0_5_0.png\n",
      "output_gpu_0_0_10_3.png\n",
      "output_gpu_0_0_2_1.png\n",
      "output_gpu_0_0_3_2.png\n",
      "output_gpu_0_0_13_3.png\n",
      "output_gpu_0_0_21_3.png\n",
      "output_gpu_0_0_0_0.png\n",
      "output_gpu_0_0_20_2.png\n",
      "output_gpu_0_0_4_2.png\n",
      "output_gpu_0_0_7_2.png\n",
      "output_gpu_0_0_8_1.png\n",
      "output_gpu_0_0_24_0.png\n",
      "output_gpu_0_0_12_2.png\n",
      "output_gpu_0_0_6_2.png\n",
      "output_gpu_0_0_22_1.png\n",
      "output_gpu_0_0_8_0.png\n",
      "output_gpu_0_0_3_3.png\n",
      "output_gpu_0_0_3_0.png\n",
      "output_gpu_0_0_19_2.png\n",
      "output_gpu_0_0_6_0.png\n",
      "output_gpu_0_0_11_2.png\n",
      "output_gpu_0_0_16_3.png\n",
      "output_gpu_0_0_19_0.png\n",
      "output_gpu_0_0_3_1.png\n",
      "output_gpu_0_0_24_3.png\n",
      "output_gpu_0_0_1_1.png\n",
      "output_gpu_0_0_5_3.png\n",
      "output_gpu_0_0_20_1.png\n",
      "output_gpu_0_0_7_0.png\n",
      "output_gpu_0_0_17_0.png\n",
      "output_gpu_0_0_23_0.png\n",
      "output_gpu_0_0_9_1.png\n",
      "output_gpu_0_0_5_2.png\n",
      "output_gpu_0_0_13_0.png\n",
      "output_gpu_0_0_12_1.png\n",
      "output_gpu_0_0_22_3.png\n",
      "output_gpu_0_0_2_2.png\n",
      "output_gpu_0_0_21_0.png\n",
      "output_gpu_0_0_0_2.png\n",
      "output_gpu_0_0_19_1.png\n",
      "output_gpu_0_0_17_1.png\n",
      "output_gpu_0_0_22_0.png\n",
      "output_gpu_0_0_12_0.png\n",
      "output_gpu_0_0_4_3.png\n",
      "output_gpu_0_0_10_2.png\n",
      "output_gpu_0_0_23_1.png\n",
      "output_gpu_0_0_21_1.png\n",
      "output_gpu_0_0_23_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:05<00:00, 19.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 1.0000483989715576 ± 1.28197261801688e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from torch.nn import functional as F\n",
    "\n",
    "generated_images = load_images_from_folder(generate_images_folder, gen_image_prefix)\n",
    "\n",
    "# Inception Score 계산\n",
    "mean_score, std_score = calculate_inception_score(generated_images)\n",
    "\n",
    "print(f\"Inception Score: {mean_score.item()} ± {std_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18470810-add3-4e26-a097-3e6b508a89ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262116d-64a1-45fd-8495-d06b3c71848c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
